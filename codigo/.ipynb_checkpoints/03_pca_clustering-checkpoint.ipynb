{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34c0586e",
   "metadata": {},
   "source": [
    "# 03_pca_clustering.ipynb\n",
    "**Dimensionality Reduction & Clustering**\n",
    "\n",
    "Now merges only numeric features to avoid duplicate metadata columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705a48c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def setup_project_paths():\n",
    "    current_dir = Path().cwd()\n",
    "    base_path = current_dir.parent if current_dir.name == 'codigo' else current_dir\n",
    "    input_path = base_path / 'corpus' / 'tei'\n",
    "    output_path = base_path / 'resultados' / 'computational-analysis'\n",
    "    return base_path, input_path, output_path\n",
    "\n",
    "BASE_PATH, INPUT_PATH, OUTPUT_PATH = setup_project_paths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f985e5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "\n",
    "# Define paths\n",
    "folder = OUTPUT_PATH / 'corpus_summary' / 'csv'\n",
    "merged_path = folder / 'merged_features.csv'\n",
    "\n",
    "# Merge numeric features only if merged file is missing\n",
    "if not merged_path.exists():\n",
    "    print(\"Merged file not found; merging numeric columns only.\")\n",
    "    files = [\n",
    "        'corpus_basic_statistics.csv',\n",
    "        'corpus_entity_frequencies.csv',\n",
    "        'corpus_linguistic_features.csv',\n",
    "        'corpus_semantic_fields.csv',\n",
    "        'corpus_stylometric_features.csv'\n",
    "    ]\n",
    "    dfs = []\n",
    "    for f in files:\n",
    "        df = pd.read_csv(folder / f)\n",
    "        key = df.columns[0]\n",
    "        numeric_cols = df.select_dtypes(include='number').columns.tolist()\n",
    "        df = df[[key] + numeric_cols]\n",
    "        dfs.append(df)\n",
    "    df_merged = dfs[0]\n",
    "    for df_part in dfs[1:]:\n",
    "        df_merged = df_merged.merge(df_part, on=key, how='inner')\n",
    "    df_merged.to_csv(merged_path, index=False)\n",
    "    print(\"Saved merged numeric features to\", merged_path)\n",
    "else:\n",
    "    print(\"Loading existing merged_features.csv\")\n",
    "\n",
    "df = pd.read_csv(merged_path)\n",
    "key = df.columns[0]\n",
    "nums = df.select_dtypes(include='number')\n",
    "X = StandardScaler().fit_transform(nums)\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=5).fit(X)\n",
    "var_ratio = pca.explained_variance_ratio_\n",
    "cum_var = var_ratio.cumsum()\n",
    "print(\"Explained variance ratios:\", var_ratio)\n",
    "print(\"Cumulative variance:\", cum_var)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(1,6), var_ratio, marker='o', label='Individual')\n",
    "plt.plot(range(1,6), cum_var, marker='x', label='Cumulative')\n",
    "plt.xlabel('PC'); plt.ylabel('Variance Ratio')\n",
    "plt.title('PCA Variance & Cumulative Variance')\n",
    "plt.legend(); plt.tight_layout()\n",
    "plt.savefig(OUTPUT_PATH / 'corpus_summary' / 'visualizations' / 'pca_variance_cumulative.png')\n",
    "plt.show()\n",
    "\n",
    "# Top loadings\n",
    "loadings = pd.DataFrame(pca.components_.T, index=nums.columns, columns=[f'PC{i+1}' for i in range(5)])\n",
    "print(\"Top 10 loadings PC1:\", loadings['PC1'].abs().nlargest(10).to_dict())\n",
    "print(\"Top 10 loadings PC2:\", loadings['PC2'].abs().nlargest(10).to_dict())\n",
    "\n",
    "# Silhouette analysis\n",
    "scores = {k: silhouette_score(X, KMeans(n_clusters=k, random_state=42).fit_predict(X)) for k in range(2,7)}\n",
    "plt.figure()\n",
    "plt.plot(list(scores.keys()), list(scores.values()), marker='o')\n",
    "plt.xlabel('Number of clusters (k)')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Silhouette Analysis')\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_PATH / 'corpus_summary' / 'visualizations' / 'silhouette.png')\n",
    "plt.show()\n",
    "print(\"Silhouette scores:\", scores)\n",
    "\n",
    "# Final clustering k=3\n",
    "df['Cluster'] = KMeans(n_clusters=3, random_state=42).fit_predict(X)\n",
    "\n",
    "# Dendrogram\n",
    "linked = linkage(X, method='ward')\n",
    "plt.figure(figsize=(10, 6))\n",
    "dendrogram(linked, labels=df[key].tolist(), leaf_rotation=90)\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_PATH / 'corpus_summary' / 'visualizations' / 'dendrogram.png')\n",
    "plt.show()\n",
    "\n",
    "df.to_csv(folder / 'clustered_features.csv', index=False)\n",
    "print(\"Saved clustered_features.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
