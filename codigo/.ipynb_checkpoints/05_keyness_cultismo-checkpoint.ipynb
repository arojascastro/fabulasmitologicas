{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50d16e8b",
   "metadata": {},
   "source": [
    "# 05_keyness_cultismo.ipynb\n",
    "**Lexical Keyness & Cultismo Frequencies**\n",
    "\n",
    "Computes log-likelihood keyness and generates a cultismo-count table from the given vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6e7499",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def setup_project_paths():\n",
    "    current_dir = Path().cwd()\n",
    "    base_path = current_dir.parent if current_dir.name == 'codigo' else current_dir\n",
    "    input_path = base_path / 'corpus' / 'tei'\n",
    "    output_path = base_path / 'resultados' / 'computational-analysis'\n",
    "    return base_path, input_path, output_path\n",
    "\n",
    "BASE_PATH, INPUT_PATH, OUTPUT_PATH = setup_project_paths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14d18d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Paths\n",
    "csv_folder = OUTPUT_PATH / 'corpus_summary' / 'csv'\n",
    "ext_folder = OUTPUT_PATH / 'extensions'\n",
    "ext_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load clusters\n",
    "clustered_path = csv_folder / 'clustered_features.csv'\n",
    "clust = pd.read_csv(clustered_path)\n",
    "key_col = clust.columns[0]\n",
    "clust = clust.rename(columns={key_col: 'filename'})\n",
    "\n",
    "# Load or generate lexical counts\n",
    "lex_path = csv_folder / 'corpus_lexical_counts.csv'\n",
    "if not lex_path.exists():\n",
    "    raw = pd.read_csv(csv_folder / 'raw_texts.csv').rename(columns={'Unnamed: 0': 'filename'})\n",
    "    docs = raw['text'].fillna('').tolist()\n",
    "    filenames = raw['filename']\n",
    "    vec = CountVectorizer(max_features=2000, stop_words='english')\n",
    "    X = vec.fit_transform(docs)\n",
    "    df_tokens = pd.DataFrame(X.toarray(), columns=vec.get_feature_names_out())\n",
    "    df_tokens.insert(0, 'filename', filenames)\n",
    "    df_tokens.to_csv(lex_path, index=False)\n",
    "else:\n",
    "    df_tokens = pd.read_csv(lex_path)\n",
    "\n",
    "# Compute log-likelihood keyness per term\n",
    "df = df_tokens.merge(clust[['filename', 'Cluster']], on='filename')\n",
    "def ll_score(k, n, K, N):\n",
    "    expected = K * n / N\n",
    "    return 2 * (k * math.log(k / expected) if k > 0 else 0)\n",
    "\n",
    "terms = [c for c in df.columns if c not in ['filename', 'Cluster']]\n",
    "N = df.shape[0]\n",
    "results = []\n",
    "for term in terms:\n",
    "    for cl in sorted(df['Cluster'].unique()):\n",
    "        sub = df[df['Cluster'] == cl]\n",
    "        k = sub[term].sum()\n",
    "        n = sub.shape[0]\n",
    "        K = df[term].sum()\n",
    "        ll = ll_score(k, n, K, N)\n",
    "        results.append({'term': term, 'Cluster': cl, 'LL': ll})\n",
    "\n",
    "ll_df = pd.DataFrame(results)\n",
    "ll_df = ll_df.sort_values(['Cluster', 'LL'], ascending=[True, False])\n",
    "ll_df.to_csv(ext_folder / 'keyness_scores.csv', index=False)\n",
    "print(\"Keyness scores saved to\", ext_folder / 'keyness_scores.csv')\n",
    "\n",
    "# Build and save cultismo count table\n",
    "vocab_path = csv_folder / 'cultismo_list.csv'\n",
    "if vocab_path.exists():\n",
    "    vocab = pd.read_csv(vocab_path).iloc[:, 0].astype(str).tolist()\n",
    "    raw = pd.read_csv(csv_folder / 'raw_texts.csv').rename(columns={'Unnamed: 0':'filename'})\n",
    "    docs = raw['text'].fillna('').str.lower().tolist()\n",
    "    filenames = raw['filename']\n",
    "    vec_cult = CountVectorizer(vocabulary=[w.lower() for w in vocab])\n",
    "    Xc = vec_cult.fit_transform(docs)\n",
    "    df_cult = pd.DataFrame(Xc.toarray(), columns=vec_cult.get_feature_names_out())\n",
    "    df_cult.insert(0, 'filename', filenames)\n",
    "    df_cult.to_csv(csv_folder / 'cultismo_list.csv', index=False)\n",
    "    print(\"Generated cultismo_list.csv with counts.\")\n",
    "    # Cultismo density per cluster\n",
    "    df_c = df_cult.merge(clust[['filename','Cluster']], on='filename')\n",
    "    cult_density = df_c.groupby('Cluster').mean().reset_index()\n",
    "    cult_density.to_csv(ext_folder / 'cultismo_density.csv', index=False)\n",
    "    print(\"Cultismo density saved to\", ext_folder / 'cultismo_density.csv')\n",
    "else:\n",
    "    print(\"Vocabulary cultismo_list.csv not found; skipping cultismo counts.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
