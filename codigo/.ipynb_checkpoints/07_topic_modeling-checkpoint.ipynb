{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d50cd389",
   "metadata": {},
   "source": [
    "# 07_topic_modeling.ipynb\n",
    "**Advanced Topic Modeling (Spanish)**\n",
    "\n",
    "This notebook adds lemmatization, adjusts LDA hyperparameters, and compares LDA vs NMF for more distinct topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c016a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def setup_project_paths():\n",
    "    current_dir = Path().cwd()\n",
    "    base_path = current_dir.parent if current_dir.name == 'codigo' else current_dir\n",
    "    input_path = base_path / 'corpus' / 'tei'\n",
    "    output_path = base_path / 'resultados' / 'computational-analysis'\n",
    "    return base_path, input_path, output_path\n",
    "\n",
    "BASE_PATH, INPUT_PATH, OUTPUT_PATH = setup_project_paths()\n",
    "(OUTPUT_PATH / 'extensions').mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25d9c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation, NMF\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# Load spaCy Spanish model for lemmatization\n",
    "try:\n",
    "    nlp = spacy.load('es_core_news_sm')\n",
    "except:\n",
    "    import spacy.cli\n",
    "    spacy.cli.download('es_core_news_sm')\n",
    "    nlp = spacy.load('es_core_news_sm')\n",
    "\n",
    "nltk.download('stopwords', quiet=True)\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('spanish') + ['si','así','pues','tan','mas','aunque','cuyo','tal','oh','cuanto','ay']\n",
    "\n",
    "# Load texts\n",
    "raw = pd.read_csv(OUTPUT_PATH/'corpus_summary'/'csv'/'raw_texts.csv')\n",
    "docs = raw['text'].fillna('').astype(str).tolist()\n",
    "\n",
    "# Lemmatize and clean tokens\n",
    "processed = []\n",
    "for doc in docs:\n",
    "    doc_nlp = nlp(re.sub(r'<[^>]+>', ' ', doc))\n",
    "    tokens = [token.lemma_.lower() for token in doc_nlp \n",
    "              if token.is_alpha and token.lemma_.lower() not in stop_words]\n",
    "    processed.append(tokens)\n",
    "\n",
    "# Build bigrams/trigrams\n",
    "bigram = gensim.models.Phrases(processed, min_count=5, threshold=10)\n",
    "trigram = gensim.models.Phrases(bigram[processed], threshold=10)\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "texts = [trigram_mod[bigram_mod[doc]] for doc in processed]\n",
    "\n",
    "# Create dictionary and corpus\n",
    "id2word = corpora.Dictionary(texts)\n",
    "id2word.filter_extremes(no_below=3, no_above=0.3)\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# Coherence grid: vary k and alpha\n",
    "results = []\n",
    "for k in [4,5,6,7,8]:\n",
    "    for alpha in ['symmetric','asymmetric']:\n",
    "        lda = gensim.models.LdaModel(corpus=corpus, id2word=id2word,\n",
    "                                     num_topics=k, random_state=42,\n",
    "                                     passes=15, alpha=alpha)\n",
    "        cm = CoherenceModel(model=lda, texts=texts, dictionary=id2word, coherence='c_v')\n",
    "        coh = cm.get_coherence()\n",
    "        results.append((k, alpha, coh))\n",
    "        print(f\"k={k}, alpha={alpha}, coherence={coh:.4f}\")\n",
    "\n",
    "# Plot coherence by k for symmetric vs asymmetric\n",
    "df_res = pd.DataFrame(results, columns=['k','alpha','coherence'])\n",
    "for alpha in df_res['alpha'].unique():\n",
    "    subset = df_res[df_res['alpha']==alpha]\n",
    "    plt.plot(subset['k'], subset['coherence'], marker='o', label=alpha)\n",
    "plt.xlabel('Número de temas')\n",
    "plt.ylabel('Coherencia c_v')\n",
    "plt.title('Coherencia LDA por alpha')\n",
    "plt.legend()\n",
    "plt.savefig(OUTPUT_PATH/'extensions'/'coherence_alpha.png')\n",
    "plt.show()\n",
    "\n",
    "# Choose best config\n",
    "best = df_res.loc[df_res['coherence'].idxmax()]\n",
    "print(\"Mejor configuración:\", best.to_dict())\n",
    "\n",
    "best_k, best_alpha = int(best['k']), best['alpha']\n",
    "\n",
    "# TF-IDF + sklearn LDA with best parameters\n",
    "vectorizer = TfidfVectorizer(max_df=0.85, min_df=3,\n",
    "                             stop_words=stop_words, token_pattern=r'(?u)\\b\\w\\w+\\b')\n",
    "X = vectorizer.fit_transform(docs)\n",
    "    # Map best_alpha to numeric prior\n",
    "doc_prior = 1.0 / best_k if best_alpha == 'symmetric' else None\n",
    "doc_prior = 1.0 / best_k if best_alpha == 'symmetric' else None\n",
    "lda_skl = LatentDirichletAllocation(\n",
    "    n_components=best_k,\n",
    "    learning_method='batch',\n",
    "    random_state=42,\n",
    "    doc_topic_prior=doc_prior\n",
    ")\n",
    "\n",
    "# NMF for comparison\n",
    "nmf = NMF(n_components=best_k, random_state=42)\n",
    "W = nmf.fit_transform(X)\n",
    "H = nmf.components_\n",
    "\n",
    "# Save term-topic matrices\n",
    "terms = vectorizer.get_feature_names_out()\n",
    "pd.DataFrame(lda_skl.components_, columns=terms)  .to_csv(OUTPUT_PATH/'extensions'/'lda_topic_terms.csv', index=False)\n",
    "pd.DataFrame(H, columns=terms)  .to_csv(OUTPUT_PATH/'extensions'/'nmf_topic_terms.csv', index=False)\n",
    "\n",
    "# Display and save bar charts for LDA\n",
    "for model, comps, prefix in [('LDA', lda_skl.components_, 'lda'), ('NMF', H, 'nmf')]:\n",
    "    for i, comp in enumerate(comps):\n",
    "        top = comp.argsort()[-10:][::-1]\n",
    "        words = [terms[j] for j in top]\n",
    "        weights = comp[top]\n",
    "        plt.figure()\n",
    "        plt.barh(words[::-1], weights[::-1])\n",
    "        plt.title(f\"{model} Tema {i+1}\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(OUTPUT_PATH/'extensions'/f'{prefix}_topic_{i+1}.png')\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
